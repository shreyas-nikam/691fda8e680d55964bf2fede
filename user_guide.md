id: 691fda8e680d55964bf2fede_user_guide
summary: Scenario-Based Model Robustness Test User Guide
feedback link: https://docs.google.com/forms/d/e/1FAIpQLSfWkOK-in_bMMoHSZfcIvAeO58PAH9wrDqcxnJABHaxiDqhSA/viewform?usp=sf_link
environments: Web
status: Published
# Scenario-Based Model Robustness Test with QuLab

## 1. Introduction to Model Robustness
Duration: 00:05:00
In this lab, we implement a scenario-based robustness test for machine learning models. The application guides users through defining stress scenarios, applying transformations to input data, generating stressed predictions, and quantitatively and visually assessing the impact on model stability.

Understanding model robustness is crucial in many domains, especially in finance, where models need to perform reliably even under adverse or unexpected market conditions. A robust model maintains its performance and prediction stability even when its input data experiences shifts or unexpected variations.

### Learning Goals:
Upon completion of using this application, users will be able to:
*   Understand how to accept a pre-trained machine learning model and a test dataset as input within the application.
*   Grasp the concept of applying user-defined stress transformations to specified input columns.
*   Define and execute multiple stress scenarios, comparing their prediction distributions to a baseline.
*   Interpret quantitative metrics, such as the mean shift in predictions, for each scenario.
*   Understand the implications of robustness test results for model design, monitoring, and operational constraints, particularly in contexts like finance.

### Robustness Concept:
At its core, model robustness involves evaluating a model's stability when its inputs change. Given a model $\hat{y} = f_\theta(x)$, which produces a prediction $\hat{y}$ based on input features $x$ and model parameters $\theta$, we assess its robustness under various stress transformations $T_s$ applied to the inputs. For each scenario $s$:
$$x^{(s)} = T_s(x), \quad \hat{y}^{(s)} = f_\theta(x^{(s)}).$$
Here, $x^{(s)}$ represents the 'stressed' version of the input data, and $\hat{y}^{(s)}$ are the predictions generated by the model on this stressed data. The goal is to compare the distributions of these stressed predictions $\hat{y}^{(s)}$ to the baseline predictions (from the unstressed $x$) to understand how the model's output changes.

## 2. Application Overview & Setup
Duration: 00:08:00
This section guides you through the initial setup, including loading a dataset and a pre-trained model. This foundation is essential for performing the robustness tests.

### Notebook Overview
This lab aims to implement a scenario-based robustness test for a given machine learning model. Upon completion, users will be able to:

*   Accept a pre-trained machine learning model and a test dataset as input.
*   Implement a function to apply user-defined stress transformations to specified input columns.
*   Define and execute multiple stress scenarios, comparing their prediction distributions to a baseline.
*   Calculate and display quantitative metrics, such as the mean shift in predictions, for each scenario.
*   Interpret the results of robustness tests and understand their implications for model design, monitoring, and operational constraints, particularly in contexts like finance.

### Setup and Library Imports
The application internally uses several Python libraries for data manipulation, machine learning model operations, and visualization. `pandas` is used for tabular data, `numpy` for numerical operations, `sklearn` for dataset loading, model training, and data splitting, and `plotly` for creating insightful visualizations of prediction distributions and shifts. These are handled automatically by the application.

### Dataset Loading and Preparation
For this lab, we use the **California Housing dataset**, a classic tabular dataset ideal for regression tasks (predicting house prices). The application automatically loads this dataset and prepares it by splitting it into training and testing sets. It also identifies key numerical columns that will be used for stress testing. These are referred to as 'volatility columns'.

Once the application starts and you navigate to this page, the data is loaded and displayed:

First 5 rows of X_test:
```
   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  Longitude
0  8.3252      41.0    6.9841   1.023810      322.00  2.555556     37.88     -122.23
1  8.3014      21.0    6.2381   0.971880      2401.00  2.109842     37.86     -122.22
2  7.2574      52.0    8.2881   1.073446      496.00  2.802260     37.85     -122.24
3  5.6431      52.0    5.8173   1.073059      558.00  2.547945     37.85     -122.25
4  3.8462      52.0    6.2819   1.081081      565.00  2.181467     37.85     -122.25
```

First 5 rows of y_test:
```
0    4.526
1    3.585
2    3.521
3    3.413
4    3.422
Name: target, dtype: float64
```

Volatility Columns:
```
['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']
```

The California Housing dataset provides several numerical features, which makes it suitable for applying "volatility" shocks. We've selected common features such as Median Income (`MedInc`), House Age (`HouseAge`), and Population (`Population`) as `vol_cols` to simulate how changes in these economic or demographic factors might impact housing price predictions.

### Pre-trained Model Initialization and Training
A pre-trained model is required to generate predictions. For demonstration purposes, the application automatically trains a simple `LinearRegression` model from `sklearn` on the training data derived from the California Housing dataset. This model serves as the subject for our robustness tests.

We have successfully trained a linear regression model. This model will now be used to generate baseline predictions and predictions under various stress scenarios to evaluate its robustness.

## 3. Understanding Baseline Predictions
Duration: 00:05:00
Before applying any stress, it's crucial to establish a `baseline` for our model's predictions. These are the predictions the model makes under normal, unstressed conditions.

### Baseline Predictions
The application generates predictions on the original `X_test` dataset. These are our baseline predictions, representing the model's normal behavior, against which all stressed scenarios will be compared.

Descriptive statistics of baseline predictions:
```
count    6192.000000
mean        2.079860
std         1.144824
min        -0.906411
25%         1.328325
50%         1.871954
75%         2.544253
max         6.636906
Name: 0, dtype: float64
```
The descriptive statistics provide a summary of our model's predictions under normal conditions. This will serve as the crucial reference point for understanding the impact of stress scenarios. You can observe the mean, standard deviation, and range of predictions.

### Visualize Baseline Predictions
Visualizing the distribution of baseline predictions helps us understand the model's typical output range and pattern before any external stressors are applied. The application displays a histogram of these predictions.

The displayed histogram shows the probability density of our model's predictions on the unstressed test data. Its shape (e.g., unimodal, bimodal, skewed) provides initial insights into the model's output characteristics. For instance, a unimodal distribution centered around the mean indicates a consistent prediction pattern.

## 4. Defining Stress Transformations
Duration: 00:10:00
The core of our robustness test lies in the ability to simulate various real-world stresses by transforming the input features. This section introduces the functions used for these transformations.

### Implementing the Stress Transformation Function (`stress_scenario_volatility`)
To simulate stress, we need a versatile function to modify our input data. The application uses `stress_scenario_volatility`, which allows us to multiply specified columns by a chosen factor. This simulates 'volatility shocks' such as sudden economic upturns or downturns.

The structure of the `stress_scenario_volatility` function is shown below:
```python
def stress_scenario_volatility(X_data, factor, vol_cols):
    """
    Applies a volatility shock to specified columns of a Pandas DataFrame.
    Arguments:
    X_data: Pandas DataFrame, the input features to be stressed.
    factor: float, the multiplicative factor.
    vol_cols: list of strings, names of columns to stress. If None, all numerical columns.
    Output:
    Pandas DataFrame, with specified columns modified by the factor.
    """
    stressed_df = X_data.copy(deep=True)
    if vol_cols is None:
        target_cols = stressed_df.select_dtypes(include=np.number).columns
    else:
        target_cols = vol_cols
    if len(target_cols) > 0:
        valid_target_cols = [col for col in target_cols if col in stressed_df.columns]
        if valid_target_cols:
            stressed_df[valid_target_cols] = stressed_df[valid_target_cols] * factor
    return stressed_df
```
The `stress_scenario_volatility` function is designed to be flexible. By changing the `factor`, we can simulate both increases (e.g., `factor=2.0` for a 100% increase) and decreases (e.g., `factor=0.5` for a 50% decrease) in the 'volatility columns'. This function will be the building block for defining our stress scenarios.

### Customizing Stress Scenarios (Advanced)
The flexibility of this framework allows for defining various types of stress beyond simple multiplicative factors. Users can implement custom functions to simulate more complex real-world phenomena, such as adding random noise, applying thresholds, or simulating specific market event impacts. The application includes another example: `stress_scenario_add_noise`.

The structure of the `stress_scenario_add_noise` function is shown below:
```python
def stress_scenario_add_noise(X_data, noise_std_dev, vol_cols):
    """    This function introduces random Gaussian noise to specified columns of a Pandas DataFrame, simulating unpredictable measurement errors or market fluctuations. It creates a deep copy of the input DataFrame to avoid modifying the original data, preserving the original test set for baseline comparisons.
Arguments:
X_data: Pandas DataFrame, the input features to be stressed.
noise_std_dev: float, the standard deviation of the Gaussian noise to add (mean is 0).
vol_cols: list of strings, the names of the columns to add noise to. If None, noise is added to all numerical columns in the DataFrame.
Output:
Pandas DataFrame, the DataFrame with specified columns having added random Gaussian noise.
    """
    X_stressed = X_data.copy(deep=True)
    if vol_cols is None:
        target_cols = X_stressed.select_dtypes(include=np.number).columns
    else:
        target_cols = vol_cols
    if len(target_cols) > 0:
        valid_target_cols = [col for col in target_cols if col in X_stressed.columns]
        for col in valid_target_cols:
            noise = np.random.normal(loc=0, scale=noise_std_dev, size=len(X_stressed))
            X_stressed[col] = X_stressed[col] + noise
    return X_stressed
```
The `stress_scenario_add_noise` function introduces random Gaussian noise to specified features, simulating unpredictable measurement errors or market fluctuations. By adding this new scenario, we demonstrate how easily the robustness test framework can be extended to cover a wider range of potential stressors.

## 5. Configuring Stress Scenarios
Duration: 00:07:00
This section shows how to define and manage various stress scenarios, from pre-defined examples to custom configurations.

### Defining Stress Scenarios
The application manages stress scenarios through a dictionary-like structure. Each scenario is configured with a specific transformation function (like `stress_scenario_volatility` or `stress_scenario_add_noise`) and its parameters (e.g., `factor`, `vol_cols`, `noise_std_dev`). This allows for easy configuration and expansion of test cases.

The application starts with three pre-defined scenarios:
```
|    | func_name                | params                                                                        |
|:|:-|:|
| vol_up | stress_scenario_volatility | {'factor': 2.0, 'vol_cols': ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']} |
| vol_down | stress_scenario_volatility | {'factor': 0.5, 'vol_cols': ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']} |
| single_col_spike | stress_scenario_volatility | {'factor': 1.5, 'vol_cols': ['MedInc']}                                       |
```
We've defined three distinct scenarios: a general 'vol_up' shock across all designated volatility columns (a 100% increase), a 'vol_down' shock (a 50% decrease), and a targeted 'single_col_spike' affecting only the `MedInc` (Median Income) column (a 50% increase). These scenarios simulate different types of potential real-world events that could impact the model's inputs.

### Adding Custom Scenarios
The application provides an interactive section in the sidebar, titled "Define Custom Stress Scenario," allowing you to create and add new stress scenarios.

1.  **Select Stress Type:** Choose between "Volatility Multiplier" (using `stress_scenario_volatility`) or "Add Gaussian Noise" (using `stress_scenario_add_noise`).
2.  **Columns to Stress:** Select which of the input features you want to apply the stress to. You can choose one or multiple columns.
3.  **New Scenario Name:** Give your custom scenario a unique and descriptive name.
4.  **Parameters:** Depending on your chosen stress type:
    *   For "Volatility Multiplier," set the `Multiplicative Factor` (e.g., `1.5` for a 50% increase).
    *   For "Add Gaussian Noise," set the `Noise Standard Deviation` (e.g., `0.5` for the spread of the random noise).
5.  **Add Scenario to List:** Click this button to add your newly configured scenario to the list of active scenarios. The table displaying current scenarios will update immediately.

<aside class="positive">
<b>Tip:</b> Experiment with different factors, noise levels, and combinations of columns to simulate a wide range of potential real-world stresses relevant to your domain.
</aside>

## 6. Executing Robustness Tests
Duration: 00:05:00
Once you have defined your desired stress scenarios (including any custom ones), the next step is to execute these tests and generate the model's predictions under each stressed condition.

### Execution Control
To run all defined stress scenarios and generate predictions, navigate to the "Execution & Results" page and click the "Run Robustness Test" button. The application will then:
1.  Take a copy of the original `X_test` data for each scenario.
2.  Apply the specified stress transformation (e.g., `stress_scenario_volatility` or `stress_scenario_add_noise`) to the chosen input columns of that data copy.
3.  Generate new predictions using the pre-trained `LinearRegression` model on the transformed (stressed) data.
4.  Store these 'stressed predictions' for subsequent analysis.

### Generating Stressed Predictions
After running the robustness test, the application confirms which scenarios were processed and provides descriptive statistics for one of the stressed prediction sets.

Scenarios processed:
```
['vol_up', 'vol_down', 'single_col_spike', 'volatility_multiplier_4', 'add_gaussian_noise_5']
```
Descriptive statistics for 'vol_up' stressed predictions:
```
count    6192.000000
mean        4.159721
std         2.289648
min        -1.812822
25%         2.656650
50%         3.743908
75%         5.088506
max        13.273812
Name: 0, dtype: float64
```
You can observe how the mean and standard deviation of the 'vol_up' scenario predictions differ from the baseline predictions (seen in Step 3). This initial comparison already hints at the impact of the stress.

## 7. Analyzing Quantitative Results
Duration: 00:08:00
While visual comparisons are intuitive, quantitative metrics provide a concise summary of the impact of each stress scenario. The application calculates the mean shift to quantify this impact.

### Calculating Quantitative Shift Metrics
A common and easily interpretable metric is the **mean shift** in predictions, which indicates the average change in the model's output due to the stress. It's calculated as the mean of stressed predictions minus the mean of baseline predictions.

The function used internally is:
```python
def calculate_mean_shift(baseline_predictions, stressed_predictions):
    """
    Calculates the quantitative difference between the mean of stressed predictions
    and the mean of baseline predictions.
    Arguments:
    baseline_predictions: NumPy array or Pandas Series, the model's predictions on
                          the original, unstressed test dataset.
    stressed_predictions: NumPy array or Pandas Series, the model's predictions on
                          the test dataset after applying a specific stress transformation.
    Output:
    float, a scalar value representing the difference between the mean of stressed
    predictions and baseline predictions.
    """
    mean_baseline = baseline_predictions.mean()
    mean_stressed = stressed_predictions.mean()
    return float(mean_stressed - mean_baseline)
```
After executing the scenarios, the application displays the calculated mean shifts for all scenarios:
```json
{
  "vol_up": 2.079860499933595,
  "vol_down": -1.0399302499667976,
  "single_col_spike": 0.40348700028202516,
  "volatility_multiplier_4": 0.5199651249916965,
  "add_gaussian_noise_5": 0.00345123479012345
}
```
The `mean_shifts` dictionary clearly shows how the average prediction changed for each scenario. A positive value indicates an increase in the average prediction, while a negative value indicates a decrease. These values provide the first quantitative measure of our model's robustness.

<aside class="negative">
<b>Warning:</b> A large mean shift (either positive or negative) suggests that the model's average prediction is significantly impacted by the stress, indicating a potential vulnerability.
</aside>

### Visualizing Quantitative Shifts (Bar Chart)
A bar chart of the mean shifts provides a consolidated view, making it easy to compare the magnitude of impact across all scenarios and quickly identify the most disruptive ones. The application generates a bar chart where each bar represents a scenario, and its height indicates the mean shift.

The bar chart offers a clear, at-a-glance summary of how each stress scenario affected the average model prediction. Scenarios with larger absolute mean shifts indicate areas where the model's stability is more significantly compromised. This visual comparison quickly highlights which types of input changes pose the biggest risk to your model's average output.

## 8. Interpreting Visual Results
Duration: 00:07:00
Beyond just the mean shift, visualizing the entire distribution of predictions under stress provides deeper insights into how the model's behavior changes.

### Visualizing Prediction Distributions for Each Scenario
To gain a deeper understanding of the impact of each stress scenario, the application visualizes the distribution of stressed predictions against the baseline. This is done by plotting overlaid histograms for the baseline predictions and each stressed scenario's predictions.

For each scenario, you will see a plot similar to this (conceptual image):

<p align="center">
  <img src="https://i.imgur.com/example_distribution_plot.png" alt="Conceptual Histogram Plot" width="600"/>
</p>

These overlaid plots visually confirm the shifts quantified earlier by the mean shift. They also reveal more subtle changes, such as:
*   **Changes in Variance:** Does the distribution become wider or narrower, indicating increased or decreased uncertainty in predictions?
*   **Skewness:** Does the distribution become more skewed to one side, suggesting the stress disproportionately affects higher or lower predictions?
*   **New Modes:** Do new peaks (modes) appear in the distribution, indicating that the model starts producing entirely different types of predictions under stress?

These insights are crucial for understanding the qualitative impact of stress beyond just an average shift.

## 9. Iterative Analysis & Conclusion
Duration: 00:05:00
Model robustness testing is often an iterative process. This section emphasizes the ability to refine and expand your analysis.

### Rerunning Analysis with Custom Scenarios
If you added new custom scenarios in Step 5, you can rerun the robustness test by clicking the "Run Robustness Test" button again. The application will re-execute all scenarios, including your new ones, and update the results. This allows for dynamic assessment of new stress conditions.

The `mean_shifts` will then include the impact of any newly added custom scenarios.
```json
{
  "vol_up": 2.079860499933595,
  "vol_down": -1.0399302499667976,
  "single_col_spike": 0.40348700028202516,
  "volatility_multiplier_4": 0.5199651249916965,
  "add_gaussian_noise_5": 0.00345123479012345,
  "my_custom_scenario_vol_spike_MedInc_Pop": 0.7512345678901234 // Example of a new scenario's shift
}
```
This iterative approach allows us to dynamically assess new stress scenarios and their effects, providing a comprehensive view of the model's behavior under various adverse conditions.

### Conclusion
This QuLab application provides a powerful framework for conducting scenario-based robustness tests on machine learning models. By systematically defining and applying various stress transformations, generating stressed predictions, and quantitatively and visually analyzing the impact, users can gain critical insights into potential model vulnerabilities.

Understanding how a model behaves under stress is paramount for responsible model deployment, especially in high-stakes environments. The insights gained from such robustness tests can inform decisions about:
*   **Model Design:** Identifying features or model architectures that are particularly sensitive to stress.
*   **Monitoring Strategies:** Setting up alerts for when input data starts to resemble stressed scenarios.
*   **Operational Constraints:** Defining conditions under which a model's predictions might become unreliable and require human intervention or a fallback mechanism.

By actively exploring different scenarios, you can build more resilient machine learning systems that stand up to real-world challenges.
